{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29644a8f",
   "metadata": {},
   "source": [
    "Задание\n",
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
    "1. Учим conv сеть для классификации\n",
    "2. Рассмотреть 2-а варианта сеточек\n",
    "2.1 Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
    "2.2 Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
    "\n",
    "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1598472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d201e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20654</th>\n",
       "      <td>1</td>\n",
       "      <td>Ну и шляпа,с роот правами бесполезная прога,ра...</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20655</th>\n",
       "      <td>5</td>\n",
       "      <td>Ок</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20656</th>\n",
       "      <td>4</td>\n",
       "      <td>Доволен</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20657</th>\n",
       "      <td>1</td>\n",
       "      <td>Песопаснасть, рут ни нужын</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20658</th>\n",
       "      <td>5</td>\n",
       "      <td>Сбербанк бомбовая компания на сегодняшний день...</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20659 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content        Date\n",
       "0           5                                     It just works!  2017-08-14\n",
       "1           4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2           5                                        Отлично все  2017-08-14\n",
       "3           5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4           5                     Очень удобно, работает быстро.  2017-08-14\n",
       "...       ...                                                ...         ...\n",
       "20654       1  Ну и шляпа,с роот правами бесполезная прога,ра...  2017-06-01\n",
       "20655       5                                                 Ок  2017-06-01\n",
       "20656       4                                            Доволен  2017-06-01\n",
       "20657       1                         Песопаснасть, рут ни нужын  2017-06-01\n",
       "20658       5  Сбербанк бомбовая компания на сегодняшний день...  2017-06-01\n",
       "\n",
       "[20659 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('отзывы за лето.xls')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33411150",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.Content, data.Rating, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d9a68f",
   "metadata": {
    "id": "VMnTsX0mMgY8"
   },
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "X_train = X_train.apply(preprocess_text)\n",
    "X_test = X_test.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1fbd03",
   "metadata": {
    "id": "C4o9QgmWI3Pw"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(X_train)\n",
    "data_corpus = train_corpus.lower()\n",
    "\n",
    "# test_corpus = \" \".join(X_test)\n",
    "# test_corpus = test_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6872b80d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Hed2ySbwJH6B",
    "outputId": "66a75988-b4e3-45aa-a483-adbdc766db03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gromo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "\n",
    "train_tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14691041",
   "metadata": {
    "id": "yJ8T0fwYJYJX"
   },
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4822fae9",
   "metadata": {
    "id": "EXOLVK1tJLT8"
   },
   "outputs": [],
   "source": [
    "train_tokens_filtered = [word for word in train_tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "694062d2",
   "metadata": {
    "id": "8qCQH5nIJoiB"
   },
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "dist = FreqDist(train_tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39b5504",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "bRQ-6wwjJrGo",
    "outputId": "ba8ebf9e-c6aa-4703-b54f-39b561e33493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['приложение',\n",
       " 'удобно',\n",
       " 'работать',\n",
       " 'удобный',\n",
       " 'отлично',\n",
       " 'нравиться',\n",
       " 'хороший',\n",
       " 'отличный',\n",
       " 'телефон',\n",
       " 'супер']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a04bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = len(set(train_tokens_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45f3f0e",
   "metadata": {
    "id": "Tdk777qGJtz4"
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26a808e0",
   "metadata": {
    "id": "5OULZgvkJzpj"
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea808a8",
   "metadata": {
    "id": "pqHlf5nNJ2hl"
   },
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83412213",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "lI4NUg_TJ6NK",
    "outputId": "5d29285d-6c2e-4c34-f307-c2e9c3c12631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14461, 150)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb8cad7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(y_train) \n",
    "test_labels = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b2f50",
   "metadata": {
    "id": "xZkrNK8OMgZA"
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4483f4f2",
   "metadata": {
    "id": "p-fmNPMmMgZA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, Flatten\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6a8c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb0592b9",
   "metadata": {
    "id": "6Dt4YyrSMgZB"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "059bbeec",
   "metadata": {
    "id": "nbMXaTTZMgZC"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bfde2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 128)          1311872   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 148, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 148, 128)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,362,497\n",
      "Trainable params: 1,362,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2d9cf5a",
   "metadata": {
    "id": "yRisairjMgZC",
    "outputId": "a59a88d7-ac76-47ce-df1b-3a40b4441849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:830 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:813 run_step  *\n        outputs = model.train_step(data)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:771 train_step  *\n        loss = self.compiled_loss(\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\losses.py:1630 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\backend.py:4827 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-39125e8c7536>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(x_train, train_labels,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           validation_split=0.1)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 _r=1):\n\u001b[0;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:830 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:813 run_step  *\n        outputs = model.train_step(data)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:771 train_step  *\n        loss = self.compiled_loss(\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\losses.py:1630 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\keras\\backend.py:4827 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\gromo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d111a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c372a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30001239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8db85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8bf5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a12523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ef915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976638c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98a6ce",
   "metadata": {
    "id": "gUQeNKRxMgZD",
    "outputId": "b189a6e5-6ff5-47d8-9ebe-e169e60a2268"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb161f",
   "metadata": {
    "id": "VtIeszxWMgZE",
    "outputId": "704df51b-2579-435e-e992-8c417ccee41e"
   },
   "outputs": [],
   "source": [
    "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc444a",
   "metadata": {
    "id": "LMIQIwctMgZE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeae60b",
   "metadata": {
    "id": "cGYcklt2MgZE"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541bed76",
   "metadata": {
    "id": "H_E_NkzBMgZE"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca9083",
   "metadata": {
    "id": "Dg1vtQCLMgZF"
   },
   "outputs": [],
   "source": [
    "train_ft = vect.fit_transform(df_train['text'])\n",
    "valid_ft = vect.transform(df_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a262a",
   "metadata": {
    "id": "Ab7EPlOuMgZF"
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d1be3",
   "metadata": {
    "id": "lJup5g1FMgZF",
    "outputId": "816aa5d6-521b-4b78-925d-76fa0ba69253"
   },
   "outputs": [],
   "source": [
    "lgr.fit(train_ft, df_train['class'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9124c2",
   "metadata": {
    "id": "ET5cYimuMgZG"
   },
   "outputs": [],
   "source": [
    "y_pred = lgr.predict(valid_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03e6e2",
   "metadata": {
    "id": "jZ5aTLzsMgZG",
    "outputId": "a5d88771-e0b5-4a48-86df-add25fa07206"
   },
   "outputs": [],
   "source": [
    "accuracy_score(df_val['class'].to_numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c233138",
   "metadata": {
    "id": "kFnpnj5_MgZG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ff74a",
   "metadata": {
    "id": "WX3QgjKmMgZG"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3556f",
   "metadata": {
    "id": "sPiRG2tvMgZH",
    "outputId": "29829c0d-468c-4907-cf05-8ac262e00c68"
   },
   "outputs": [],
   "source": [
    "df_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91b5ca",
   "metadata": {
    "id": "eFB4RICGMgZH"
   },
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=df_train['text'].apply(str.split), size=100, window=5, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a2f24",
   "metadata": {
    "id": "8n9xJi4vMgZH",
    "outputId": "8ecb4f91-00ac-41f5-e875-acd313e5ae90"
   },
   "outputs": [],
   "source": [
    "modelW2V.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320bafb",
   "metadata": {
    "id": "QIxUX9d8MgZI"
   },
   "outputs": [],
   "source": [
    "vect_idf = TfidfVectorizer()\n",
    "vect_idf.fit_transform(df_train['text'])\n",
    "tfidf = dict(zip(vect_idf.get_feature_names(), vect_idf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8d426",
   "metadata": {
    "id": "b_iYzXlRMgZI",
    "outputId": "5be3c323-17be-404f-b1e4-1b8869ea8638"
   },
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ebeaa",
   "metadata": {
    "id": "cfgUTb-7MgZJ"
   },
   "outputs": [],
   "source": [
    "rt = vect_idf.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db106f8",
   "metadata": {
    "id": "t5USS23aMgZJ",
    "outputId": "d6df588c-29f6-4a44-8ebf-4668c727349b"
   },
   "outputs": [],
   "source": [
    "tfidf['alisachachka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bb3bc",
   "metadata": {
    "id": "XSfvMxa1MgZJ",
    "outputId": "31695a88-db30-4b9a-f210-e2c1727350fb"
   },
   "outputs": [],
   "source": [
    "vect_idf.idf_[vect_idf.vocabulary_['alisachachka']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e9c07",
   "metadata": {
    "id": "qGZ8LJ24MgZJ",
    "outputId": "270d4956-2740-41a7-9f8e-a7ad6935e6b8"
   },
   "outputs": [],
   "source": [
    "len(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b995933",
   "metadata": {
    "id": "6wU76Ps1MgZK"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7c86d",
   "metadata": {
    "id": "KMYzQh8uMgZK"
   },
   "outputs": [],
   "source": [
    "max_idf = max(vect_idf.idf_)\n",
    "\n",
    "word2weight = defaultdict(\n",
    "    lambda: max_idf,\n",
    "    [(w, vect_idf.idf_[i]) for w, i in vect_idf.vocabulary_.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfde3f8",
   "metadata": {
    "id": "8j7mm8-QMgZK"
   },
   "outputs": [],
   "source": [
    "def get_vect_mean(txt):\n",
    "    vector_w2v = np.zeros(100)\n",
    "    n_w2v = 0\n",
    "    for wrd in txt.split():\n",
    "        if wrd in modelW2V:\n",
    "            vector_w2v += modelW2V[wrd]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector_w2v = vector_w2v / n_w2v\n",
    "    return vector_w2v\n",
    "\n",
    "def get_vect_idf(txt):\n",
    "    vector_w2v = np.zeros(100)\n",
    "    n_w2v = 0\n",
    "    for wrd in txt.split():\n",
    "        if wrd in modelW2V:\n",
    "            iddf_ = tfidf.get(wrd, 1.)\n",
    "            vector_w2v += modelW2V[wrd]*iddf_\n",
    "            n_w2v += iddf_\n",
    "    if n_w2v > 0:\n",
    "        vector_w2v = vector_w2v / n_w2v\n",
    "    return vector_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef4903",
   "metadata": {
    "id": "7CAbtlc5MgZL"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680442df",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "0fb91ab0ab024c2382ab67fa73b4bd48",
      "50510615910e4fa4ba76fc23f4d9ab2b"
     ]
    },
    "id": "TzbO7LNOMgZL",
    "outputId": "4867c71c-e656-44ca-e147-febf5e2119c9"
   },
   "outputs": [],
   "source": [
    "arr_vect = []\n",
    "for txt in tqdm_notebook(df_train['text']):\n",
    "    arr_vect.append(get_vect_mean(txt))\n",
    "    \n",
    "arr_vect_valid = []\n",
    "for txt in tqdm_notebook(df_val['text']):\n",
    "    arr_vect_valid.append(get_vect_mean(txt))\n",
    "    \n",
    "train_w2v = np.asarray(arr_vect)    \n",
    "valid_w2v = np.asarray(arr_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7066142b",
   "metadata": {
    "id": "Z5YKLItiMgZL"
   },
   "outputs": [],
   "source": [
    "lgr_w2v = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61974a8d",
   "metadata": {
    "id": "Q6SnxEwqMgZM",
    "outputId": "1fb641fb-d111-49f3-82cd-27d0544231f6"
   },
   "outputs": [],
   "source": [
    "lgr_w2v.fit(train_w2v, df_train['class'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765930ee",
   "metadata": {
    "id": "qUQlJRa8MgZM"
   },
   "outputs": [],
   "source": [
    "y_pred = lgr_w2v.predict(valid_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4adb7",
   "metadata": {
    "id": "2nTiUw23MgZM",
    "outputId": "234c6c46-85c0-4252-f5f4-cb1c41e99c79"
   },
   "outputs": [],
   "source": [
    "accuracy_score(df_val['class'].to_numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a81ffb",
   "metadata": {
    "id": "ND8FKFa2MgZN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989edca",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "8b9d409c86944bd6a9e9787b45cb26eb",
      "13edd68589cd4890a7ee75636ff4f223"
     ]
    },
    "id": "K9YfE5njMgZN",
    "outputId": "6a26f612-17dc-47cb-fa9d-e419018d0056"
   },
   "outputs": [],
   "source": [
    "arr_vect = []\n",
    "for txt in tqdm_notebook(df_train['text']):\n",
    "    arr_vect.append(get_vect_idf(txt))\n",
    "    \n",
    "arr_vect_valid = []\n",
    "for txt in tqdm_notebook(df_val['text']):\n",
    "    arr_vect_valid.append(get_vect_idf(txt))\n",
    "    \n",
    "train_w2v = np.asarray(arr_vect)    \n",
    "valid_w2v = np.asarray(arr_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04052564",
   "metadata": {
    "id": "wNWcli2PMgZN",
    "outputId": "fa0aad71-36b4-44fb-b55c-8c4536da0039"
   },
   "outputs": [],
   "source": [
    "lgr_w2v = LogisticRegression()\n",
    "lgr_w2v.fit(train_w2v, df_train['class'].to_numpy())\n",
    "y_pred = lgr_w2v.predict(valid_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbd02b",
   "metadata": {
    "id": "vo0bS0yhMgZO",
    "outputId": "07097876-e4f8-47b4-bfd4-9972ea989a26"
   },
   "outputs": [],
   "source": [
    "accuracy_score(df_val['class'].to_numpy(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a32412",
   "metadata": {
    "id": "-yg5JrZxMgZO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec25815",
   "metadata": {
    "id": "1wP3Q9PeMgZO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a14bba",
   "metadata": {
    "id": "Tskwb78hMgZP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e53053",
   "metadata": {
    "id": "IxR11Ed7MgZP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3c6660",
   "metadata": {
    "id": "qFIaRPhfMgZU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d3b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
